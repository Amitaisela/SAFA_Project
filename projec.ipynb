{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "import string\n",
    "from convokit import Corpus, download\n",
    "import ast\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL's\n",
    "# https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "# https://convokit.cornell.edu/documentation/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed RNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDRIVE_DIR = \"/gdrive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/omershubi/neural-complexity.git rnn\n",
    "mkdir -p rnn/data/ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p gdrive/\n",
    "mkdir -p gdrive/corpus_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO rnn/data/ptb/ptb_tok_train.txt https://gist.githubusercontent.com/omershubi/cdd4231472d6188f03ab21e2b2729fee/raw/e1b4c764561fd038470830534baaa220b0eb4c6d/ptb_tok_train.txt\n",
    "!wget -qO rnn/data/ptb/ptb_tok_dev.txt https://gist.githubusercontent.com/omershubi/31eff71b74dfb8cfe93d1a9acf8ab523/raw/094d3094b06beb92cd7fd0496710cf43273f8c64/ptb_tok_dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp rnn/data/ptb/* \"gdrive/corpus_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OG RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_to_use = f\"../gdrive/ptb_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd rnn && python main.py --cuda --model_file \"../gdrive/ptb_model.pt\" \\\n",
    "    --epochs \"$NUM_OF_EPOCHS\" \\\n",
    "    --vocab_file \"../gdrive/ptb_vocab.txt\" \\\n",
    "    --tied --data_dir \"../gdrive/corpus_data\" --trainfname ptb_tok_train.txt --validfname ptb_tok_dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd rnn && python main.py --cuda --model_file \"$checkpoint_to_use\" \\\n",
    "    --vocab_file \"../gdrive/ptb_vocab.txt\" --data_dir './data' \\\n",
    "    --testfname 'brown.txt' --test --words --nopp > \"../gdrive/rnn_surprisals.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = pd.read_csv('https://gist.githubusercontent.com/omershubi/f19f77f5157f7ba7ea1adf72a72847da/raw/d5d553b1217ea70fe3261ce5d9a0532f29769817/5gram_surprisals.tsv', index_col=False, sep='\\t')\n",
    "readingTimes = pd.read_csv('https://gist.githubusercontent.com/omershubi/01b55eab89b81dc882055e0d27d61016/raw/046dbb7f0586b5dc1a368ee882f2cb923caad3df/brown-spr-data-for-pset.csv', index_col=0).sort_values(by='code')\n",
    "rnn = pd.read_csv(f'./gdrive/rnn_surprisals.tsv',sep=' ')\n",
    "rnn.rename(columns={'word': 'token'}, inplace=True)\n",
    "rnn.rename(columns={'surp': 'surprisal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text: str) -> str:\n",
    "    if text == '<unk>':\n",
    "        return text\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def harmonize(rt_data: pd.DataFrame, surprs_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create copies of the input DataFrames to avoid modifying the originals\n",
    "    crt_data = rt_data.copy()\n",
    "    csurprs_data = surprs_data.copy()\n",
    "    \n",
    "    # Drop unnecessary columns and remove duplicates from rt_data\n",
    "    crt_data.drop(['subject', 'word_in_exp', 'time'], axis=1, inplace=True)\n",
    "    crt_data.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remove end-of-sentence tokens from surprs_data\n",
    "    csurprs_data = csurprs_data[csurprs_data['token'] != '</s>']\n",
    "\n",
    "    # Identify and flag words containing spaces in crt_data\n",
    "    crt_data['remove_flag'] = crt_data['word'].apply(lambda word: ' ' in word)\n",
    "    \n",
    "    # Split and explode words containing spaces to match tokenization\n",
    "    crt_data['word'] = crt_data['word'].apply(lambda word: word.split())\n",
    "    crt_data = crt_data.explode('word')\n",
    "    \n",
    "    # Remove punctuation from both DataFrames\n",
    "    crt_data['word'] = crt_data['word'].apply(remove_punctuations)\n",
    "    csurprs_data['token'] = csurprs_data['token'].apply(remove_punctuations)\n",
    "\n",
    "    # Reset indices for merging\n",
    "    crt_data.reset_index(drop=True, inplace=True)\n",
    "    csurprs_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge DataFrames based on matching indices and drop unnecessary columns\n",
    "    if all(col in csurprs_data.columns for col in ['sentence_id', 'token_id']):\n",
    "        keys_harmony = crt_data.merge(csurprs_data, left_index=True, right_index=True).drop(['token_id'], axis=1)\n",
    "    else:\n",
    "        keys_harmony = crt_data.merge(csurprs_data, left_index=True, right_index=True).drop([ 'entropy', 'entred'], axis=1)\n",
    "\n",
    "    # Filter out flagged tokens and OOV words\n",
    "    keys_harmony = keys_harmony[keys_harmony['remove_flag'] == False]\n",
    "    keys_harmony = keys_harmony[keys_harmony['token'] != '<unk>']\n",
    "    \n",
    "    # Drop additional columns and merge with original rt_data\n",
    "    keys_harmony.drop(['text_id', 'text_pos', 'remove_flag', 'word'], axis=1, inplace=True)\n",
    "    final_harmony = keys_harmony.merge(rt_data, on='code')\n",
    "    \n",
    "    return final_harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize the datasets\n",
    "ngram_harm = harmonize(readingTimes, ngram)\n",
    "rnn_harm = harmonize(readingTimes, rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## closed analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_correlations(ngram, rnn, df1_key, df2_key, rt_column):\n",
    "    # Calculate the correlation coefficients and p-values\n",
    "    ngram_corr, _ = pearsonr(ngram[df1_key], ngram[rt_column])\n",
    "    rnn_corr, _ = pearsonr(rnn[df2_key], rnn[rt_column])\n",
    "    # Compare the correlation coefficients\n",
    "    if ngram_corr > rnn_corr:\n",
    "        percnt = (ngram_corr - rnn_corr) / rnn_corr * 100\n",
    "        result = f\"n_gram has a higher correlation with human reading times ( specifically {percnt:.4}% higher ).\"\n",
    "    elif ngram_corr < rnn_corr:\n",
    "        percnt = (rnn_corr - ngram_corr) / ngram_corr * 100\n",
    "        result = f\"RNN has a higher correlation with human reading times ( specifically {percnt:.4}% higher ).\"\n",
    "    else:\n",
    "        result = \"Both models have the same correlation with human reading times.\"\n",
    "\n",
    "    return result, ngram_corr, rnn_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, ngram_correlation, rnn_correlation = compare_model_correlations(ngram_harm, rnn_harm, \"surprisal\", \"surprisal\",'time')\n",
    "print(result)\n",
    "print(f\"\\nngram Correlation:\\t{ngram_correlation}\\nRNN Correlation:\\t{rnn_correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_surprisals = ngram_harm['surprisal']\n",
    "rnn_surprisals = rnn_harm['surprisal']\n",
    "\n",
    "plt.scatter(ngram_surprisals, rnn_surprisals)\n",
    "plt.xlabel('n-gram Model Surprisal')\n",
    "plt.ylabel('RNN Surprisal')\n",
    "plt.title('Relationship between n-gram Model Surprisal and RNN Surprisal')\n",
    "\n",
    "# Add linear line\n",
    "slope, intercept = np.polyfit(ngram_surprisals, rnn_surprisals, 1)\n",
    "x = np.linspace(min(ngram_surprisals), max(ngram_surprisals), 100)\n",
    "y = slope * x + intercept\n",
    "plt.plot(x, y, color='red', label='Linear')\n",
    "# plt.savefig('surprisal_relationship.png')  # Save the plot as an image file\n",
    "# add the eqaution of the line\n",
    "plt.text(10, 0.5, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_surprisals = ngram_harm['surprisal']\n",
    "rnn_surprisals = rnn_harm['surprisal']\n",
    "\n",
    "plt.scatter(ngram_surprisals, rnn_surprisals)\n",
    "plt.xlabel('n-gram Model Surprisal')\n",
    "plt.ylabel('RNN Surprisal')\n",
    "plt.title('Relationship between n-gram Model Surprisal and RNN Surprisal')\n",
    "\n",
    "# Add linear line\n",
    "slope, intercept = np.polyfit(ngram_surprisals, rnn_surprisals, 1)\n",
    "x = np.linspace(min(ngram_surprisals), max(ngram_surprisals), 100)\n",
    "y = slope * x + intercept\n",
    "plt.plot(x, y, color='red', label='Linear')\n",
    "# plt.savefig('surprisal_relationship.png')  # Save the plot as an image file\n",
    "# add the eqaution of the line\n",
    "plt.text(10, 0.5, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting points here for us are points where the difference between the surprisal value of the ngram and the RNN are the highest. Lets find the top 5 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only word and surprisal for RNN, and keep only unique rows\n",
    "rnn_intrest = rnn_harm[['token', 'surprisal', 'sentid']].drop_duplicates()\n",
    "ngram_intrest = ngram_harm[['token', 'surprisal','sentence_id']].drop_duplicates()\n",
    "\n",
    "k = 5\n",
    "# get the top k words with the highest surprisal difference\n",
    "top_k_uniqeue = pd.merge(rnn_intrest, ngram_intrest, on='token', how='inner', suffixes=('_rnn', '_ngram'))\n",
    "top_k_uniqeue['diff'] = abs(top_k_uniqeue['surprisal_rnn'] - top_k_uniqeue['surprisal_ngram'])\n",
    "top_k_uniqeue = top_k_uniqeue.sort_values(by='diff', ascending=False).drop_duplicates(subset='token').head(k)\n",
    "top_k_uniqeue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = pd.merge(rnn_intrest, ngram_intrest, on='token', how='inner', suffixes=('_rnn', '_ngram'))\n",
    "top_k['diff'] = abs(top_k['surprisal_rnn'] - top_k['surprisal_ngram'])\n",
    "top_k = top_k.sort_values(by='diff', ascending=False).head(k)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = pd.concat([top_k_uniqeue, top_k], axis=0)\n",
    "in_both = conc[conc.duplicated(keep=False)].drop_duplicates()\n",
    "in_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_surprisals = ngram_harm['surprisal']\n",
    "rnn_surprisals = rnn_harm['surprisal']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(ngram_surprisals, rnn_surprisals, color='blue', label='All other points')\n",
    "plt.scatter(top_k['surprisal_rnn'], top_k['surprisal_ngram'], color='red', label=f'top {k} points with the highest difference')\n",
    "plt.scatter(top_k_uniqeue['surprisal_rnn'], top_k_uniqeue['surprisal_ngram'], color='green', label = f'top {k} uniqeue points with the highest difference')\n",
    "plt.scatter(in_both['surprisal_rnn'], in_both['surprisal_ngram'], color='yellow', label='Points in both top k and top k uniqeue')\n",
    "\n",
    "plt.xlabel('n-gram Model Surprisal')\n",
    "plt.ylabel('RNN Surprisal')\n",
    "plt.title('Relationship between n-gram Model Surprisal and RNN Surprisal')\n",
    "\n",
    "# Add linear line\n",
    "slope, intercept = np.polyfit(ngram_surprisals, rnn_surprisals, 1)\n",
    "x = np.linspace(min(ngram_surprisals), max(ngram_surprisals), 100)\n",
    "y = slope * x + intercept\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# add the equation of the line\n",
    "plt.text(10, 0.5, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_sent_id = top_k['sentid'].values\n",
    "top_k_uniqeue_sent_id = top_k_uniqeue['sentid'].values\n",
    "in_both_sent_id = in_both['sentid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances_top_k = []\n",
    "sentances_top_k_uniqeue = []\n",
    "sentances_in_both = []\n",
    "\n",
    "for sent_id in top_k_sent_id:\n",
    "    sent = list(rnn_harm[rnn_harm['sentid']==sent_id].drop_duplicates(subset='token')['token'])\n",
    "    sentances_top_k.append(' '.join(sent))\n",
    "    \n",
    "for sent_id in top_k_uniqeue_sent_id:\n",
    "    sent = list(rnn_harm[rnn_harm['sentid']==sent_id].drop_duplicates(subset='token')['token'])\n",
    "    sentances_top_k_uniqeue.append(' '.join(sent))\n",
    "    \n",
    "for sent_id in in_both_sent_id:\n",
    "    sent = list(rnn_harm[rnn_harm['sentid']==sent_id].drop_duplicates(subset='token')['token'])\n",
    "    sentances_in_both.append(' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances_in_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances_top_k_uniqeue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances_top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sentences contain word ( or word sequences ) that are grammatically weird, lacking coherence, or just rare (e.g. \"York State Guard proved unable to keep any kind of mail\" ). The n-gram model - that relies on \"local\" patterns - struggles more with these combinations, while RNN model - that can capture \"global\" pattrens, might better recognize that these sentences don't make sense in a broader context, and thats why we see that it is usually giving a higher surprisal score then the ngram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mean_rt  = rnn_harm[rnn_harm['time'] > 0].reset_index() \n",
    "surprisal_data = positive_mean_rt['surprisal'].reset_index()\n",
    "\n",
    "previous_surprisal = [0] \n",
    "\n",
    "for i in range(1, len(surprisal_data['surprisal'])):\n",
    "    previous_surprisal.append(surprisal_data['surprisal'][i - 1])\n",
    "\n",
    "surprisal_data['prev_surprisal'] = previous_surprisal\n",
    "\n",
    "# Calculate RNN probabilities for previous and current surprisal values\n",
    "rnn_prob_prev = 1 / (2 ** surprisal_data['prev_surprisal'])\n",
    "rnn_prob_current = 1 / (2 ** surprisal_data['surprisal'])\n",
    "\n",
    "# Extract reading times\n",
    "reading_times = list(positive_mean_rt[positive_mean_rt['time'] > 0]['time'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_coef_prev, intercept_prev = np.polyfit(rnn_prob_prev, reading_times, 1)\n",
    "regression_coef_current, intercept_current = np.polyfit(rnn_prob_current, reading_times, 1)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot RNN probability (previous word) vs next word's reading time with regression line and equation\n",
    "sns.regplot(x=rnn_prob_prev, y=reading_times, ax=ax1, scatter_kws={'color': 'orange'}, line_kws={'color': 'red'})\n",
    "equation_prev = f'y = {regression_coef_prev:.2f}x + {intercept_prev:.2f}'\n",
    "ax1.text(0.4, 0.8, equation_prev, transform=ax1.transAxes, fontsize=12, verticalalignment='top')\n",
    "ax1.set_xlabel('RNN Predicted Probability of Previous Word')\n",
    "ax1.set_ylabel('Reading Time of Next Word (ms)')\n",
    "ax1.set_title('RNN Probability of Previous Word vs Next Word Reading Time')\n",
    "\n",
    "# Plot RNN probability (current word) vs current word's reading time with regression line and equation\n",
    "sns.regplot(x=rnn_prob_current, y=reading_times, ax=ax2, scatter_kws={'color': 'blue'}, line_kws={'color': 'red'})\n",
    "equation_current = f'y = {regression_coef_current:.2f}x + {intercept_current:.2f}'\n",
    "ax2.text(0.4, 0.8, equation_current, transform=ax2.transAxes, fontsize=12, verticalalignment='top')\n",
    "ax2.set_xlabel('RNN Predicted Probability of Current Word')\n",
    "ax2.set_ylabel('Reading Time of Current Word (ms)')\n",
    "ax2.set_title('RNN Probability of Current Word vs Current Word Reading Time')\n",
    "\n",
    "# Set x-axis ticks\n",
    "ax1.set_xticks(np.arange(0.1, 1.1, 0.1))\n",
    "ax2.set_xticks(np.arange(0.1, 1.1, 0.1))\n",
    "\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both graphs show similar trends: as the RNN predicted probability increases, reading time generally decreases. There is a high concentration of data points with lower reading times (below 2000 ms) across all probabilities. The slopes of the regression lines are comparable, suggesting a similar effect of probability on reading time for both previous and current words. However, there are some outliers with very high reading times (up to about 11000 ms), particularly at lower probabilities. The spread of reading times decreases with increasing probability, suggesting more consistent reading times for high-probability words.\n",
    "\n",
    "Overall, words with higher predicted probabilities are read faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rnn_harm.copy()\n",
    "words = rnn_harm['word']\n",
    "log_freq_dict = {}\n",
    "for word in words:\n",
    "  if word in log_freq_dict:\n",
    "    log_freq_dict[word] += 1\n",
    "  else:\n",
    "    log_freq_dict[word] = 1\n",
    "s0=[]\n",
    "for word in log_freq_dict:\n",
    "  log_freq_dict[word] = math.log(log_freq_dict[word])\n",
    "for word in words:\n",
    "  s0.append(log_freq_dict[word])\n",
    "\n",
    "sur = rnn_harm['surprisal'].reset_index()\n",
    "sur['prob'] = 1 / (2 ** sur['surprisal'])\n",
    "s1=[]\n",
    "s1.append(0)\n",
    "for i in range(1, len(sur['prob'])):\n",
    "  s1.append(sur['prob'][i-1])\n",
    "df['log_frq'] = s0\n",
    "df['prev_prob']=s1\n",
    "df['prob'] = sur['prob']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import LinearGAM, s, f\n",
    "\n",
    "\n",
    "X = df[['log_frq', 'wlen', 'surprisal', 'prob', 'prev_prob']].to_numpy()\n",
    "y = df.time.values\n",
    "\n",
    "## model\n",
    "gam = LinearGAM(s(0, n_splines=5) + s(1, n_splines=5) + s(2, n_splines=5) + s(3, n_splines=5)+ s(4, n_splines=5)).fit(X, y)\n",
    "titles = ['log-frequency', 'word_length', 'surprisal', 'probability', 'prev probability']\n",
    "for i in range(5):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=0.95)[1], c='r', ls='--')\n",
    "    ax.set_title(titles[i])\n",
    "    plt.savefig(f'pygam_{i}.png')  # Save the plot as an image file\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p wikitext2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_to_use_wikitext2 = f\"../wikitext2/wikitext2_model.pt\"\n",
    "model_file_wikitext2 = f\"../wikitext2/wikitext2_model.pt\"\n",
    "vocab_file_wikitext2 = f\"../wikitext2/wikitext2_vocab.txt\"\n",
    "data_dir_wikitext2= f\"../rnn/data/wikitext-2\"\n",
    "trainfname_wikitext2 = f\"train.txt\"\n",
    "validfname_wikitext2 = f\"valid.txt\"\n",
    "surprisals_wikitext2 = f\"../wikitext2/rnn_surprisals_wikitext2.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd rnn && python main.py --cuda --model_file \"$model_file_wikitext2\" \\\n",
    "--epochs \"$NUM_OF_EPOCHS\" \\\n",
    "--vocab_file \"$vocab_file_wikitext2\" \\\n",
    "--tied --data_dir \"$data_dir_wikitext2\" --trainfname \"$trainfname_wikitext2\" --validfname \"$validfname_wikitext2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd rnn && python main.py --cuda --model_file \"$checkpoint_to_use_wikitext2\" \\\n",
    "--vocab_file \"$vocab_file_wikitext2\" --data_dir './data' \\\n",
    "--testfname 'brown.txt' --test --words --nopp > \"$surprisals_wikitext2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_surprisals_wikitext2 = pd.read_csv(f'./wikitext2/rnn_surprisals_wikitext2.tsv',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Regular expression pattern to preserve contractions\n",
    "CONTRACTIONS_PATTERN = re.compile(r\"\\b(?:[A-Za-z']+)\\b(?:[A-Za-z']*)\")\n",
    "\n",
    "def custom_tokenize(text):\n",
    "    tokens = CONTRACTIONS_PATTERN.findall(text)\n",
    "    return tokens\n",
    "\n",
    "# Step 1: Train n-gram model on Wikitext-2\n",
    "\n",
    "# Load and preprocess Wikitext-2 data\n",
    "with open('rnn/data/wikitext-2/train.txt', 'r') as f:\n",
    "    wikitext = f.read()\n",
    "\n",
    "# Use custom tokenizer to preserve contractions\n",
    "wikitext_sentences = nltk.sent_tokenize(wikitext.lower())\n",
    "wikitext_tokens = [custom_tokenize(sentence) for sentence in wikitext_sentences]\n",
    "\n",
    "# Create 5-grams for Wikitext-2 with sentence-level padding\n",
    "wikitext_five_grams = []\n",
    "for sentence in wikitext_tokens:\n",
    "    padded_tokens = ['<s>'] * 4 + sentence + ['</s>']\n",
    "    wikitext_five_grams.extend(list(ngrams(padded_tokens, 5)))\n",
    "\n",
    "wikitext_four_grams = []\n",
    "for sentence in wikitext_tokens:\n",
    "    padded_tokens = ['<s>'] * 4 + sentence + ['</s>']\n",
    "    wikitext_four_grams.extend(list(ngrams(padded_tokens, 4)))\n",
    "\n",
    "# Count occurrences of 5-grams and 4-grams in Wikitext-2\n",
    "five_gram_counts = Counter(wikitext_five_grams)\n",
    "four_gram_counts = Counter(wikitext_four_grams)\n",
    "\n",
    "# Step 2: Calculate surprisals on Brown corpus\n",
    "\n",
    "# Load and preprocess Brown corpus data\n",
    "with open('rnn/data/brown.txt', 'r') as f:\n",
    "    brown_text = f.read()\n",
    "\n",
    "# Use custom tokenizer to preserve contractions\n",
    "brown_sentences = nltk.sent_tokenize(brown_text.lower())\n",
    "brown_tokens = [custom_tokenize(sentence) for sentence in brown_sentences]\n",
    "\n",
    "# Pad and flatten Brown tokens, and create sentence and token indices\n",
    "brown_padded_tokens = []\n",
    "sentence_ids = []\n",
    "token_ids = []\n",
    "sentence_id = 1\n",
    "\n",
    "for sentence in brown_tokens:\n",
    "    padded_sentence = ['<s>'] * 4 + sentence\n",
    "    brown_padded_tokens.extend(padded_sentence)\n",
    "    sentence_ids.extend([sentence_id] * len(padded_sentence))\n",
    "    token_ids.extend(range(1, len(padded_sentence) + 1))\n",
    "    sentence_id += 1\n",
    "\n",
    "# Function to calculate surprisals based on Wikitext-2 model\n",
    "def calculate_surprisals(tokens, five_gram_counts, four_gram_counts):\n",
    "    surprisals = []\n",
    "    for ngram in ngrams(tokens, 5):\n",
    "        four_gram = ngram[:-1]\n",
    "        if four_gram_counts[four_gram] > 0:\n",
    "            prob = five_gram_counts[ngram] / four_gram_counts[four_gram]\n",
    "            if prob > 0:\n",
    "                surprisal = -math.log2(prob)\n",
    "            else:\n",
    "                surprisal = float('inf')  # Assign infinity for zero probability\n",
    "        else:\n",
    "            surprisal = float('inf')  # Assign infinity for unseen contexts\n",
    "        surprisals.append(surprisal)\n",
    "    return surprisals\n",
    "\n",
    "# Calculate surprisals for the Brown corpus\n",
    "brown_surprisals = calculate_surprisals(brown_padded_tokens, five_gram_counts, four_gram_counts)\n",
    "\n",
    "# Adjust indices and tokens for DataFrame\n",
    "adjusted_token_ids = [x - 4 for x in token_ids[4:]]\n",
    "\n",
    "# Create DataFrame for Brown corpus surprisals\n",
    "df_brown_surprisals = pd.DataFrame({\n",
    "    'sentence_id': sentence_ids[4:],  # Exclude padding tokens\n",
    "    'token_id': adjusted_token_ids,   # Exclude padding tokens\n",
    "    'token': brown_padded_tokens[4:], # Exclude padding tokens and final `</s>`\n",
    "    'surprisal': brown_surprisals\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brown_surprisals['token'] = df_brown_surprisals.apply(lambda row: '<unk>' if row['surprisal'] == float('inf') else row['token'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readingTimes = pd.read_csv('https://gist.githubusercontent.com/omershubi/01b55eab89b81dc882055e0d27d61016/raw/046dbb7f0586b5dc1a368ee882f2cb923caad3df/brown-spr-data-for-pset.csv', index_col=0).sort_values(by='code')\n",
    "rnn_wiki = pd.read_csv(f'./wikitext2/rnn_surprisals_wikitext2.tsv',sep=' ')\n",
    "rnn_wiki.rename(columns={'word': 'token'}, inplace=True)\n",
    "rnn_wiki.rename(columns={'surp': 'surprisal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = df_brown_surprisals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text: str) -> str:\n",
    "    if text == '<unk>':\n",
    "        return text\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def harmonize(rt_data: pd.DataFrame, surprs_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create copies of the input DataFrames to avoid modifying the originals\n",
    "    crt_data = rt_data.copy()\n",
    "    csurprs_data = surprs_data.copy()\n",
    "    \n",
    "    # Drop unnecessary columns and remove duplicates from rt_data\n",
    "    crt_data.drop(['subject', 'word_in_exp', 'time'], axis=1, inplace=True)\n",
    "    crt_data.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remove end-of-sentence tokens from surprs_data\n",
    "    csurprs_data = csurprs_data[csurprs_data['token'] != '</s>']\n",
    "\n",
    "    # Identify and flag words containing spaces in crt_data\n",
    "    crt_data['remove_flag'] = crt_data['word'].apply(lambda word: ' ' in word)\n",
    "    \n",
    "    # Split and explode words containing spaces to match tokenization\n",
    "    crt_data['word'] = crt_data['word'].apply(lambda word: word.split())\n",
    "    crt_data = crt_data.explode('word')\n",
    "    \n",
    "    # Remove punctuation from both DataFrames\n",
    "    crt_data['word'] = crt_data['word'].apply(remove_punctuations)\n",
    "    csurprs_data['token'] = csurprs_data['token'].apply(remove_punctuations)\n",
    "\n",
    "    # Reset indices for merging\n",
    "    crt_data.reset_index(drop=True, inplace=True)\n",
    "    csurprs_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge DataFrames based on matching indices and drop unnecessary columns\n",
    "    if all(col in csurprs_data.columns for col in ['sentence_id', 'token_id']):\n",
    "        keys_harmony = crt_data.merge(csurprs_data, left_index=True, right_index=True).drop(['token_id'], axis=1)\n",
    "    else:\n",
    "        keys_harmony = crt_data.merge(csurprs_data, left_index=True, right_index=True).drop([ 'entropy', 'entred'], axis=1)\n",
    "\n",
    "    # Filter out flagged tokens and OOV words\n",
    "    keys_harmony = keys_harmony[keys_harmony['remove_flag'] == False]\n",
    "    keys_harmony = keys_harmony[keys_harmony['token'] != '<unk>']\n",
    "    \n",
    "    # Drop additional columns and merge with original rt_data\n",
    "    keys_harmony.drop(['text_id', 'text_pos', 'remove_flag', 'word'], axis=1, inplace=True)\n",
    "    final_harmony = keys_harmony.merge(rt_data, on='code')\n",
    "    \n",
    "    return final_harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize the datasets\n",
    "rnn_wiki_harm = harmonize(readingTimes, rnn_wiki)\n",
    "ngram_wiki_harm = harmonize(readingTimes, ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_wiki_harm.rename(columns={'sentence_id': 'sentid'}, inplace=True)\n",
    "# Convert the 'token' column to lowercase\n",
    "rnn_wiki_harm['token'] = rnn_wiki_harm['token'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_ngran_rnn = pd.merge(rnn_wiki_harm.drop(columns=['surprisal']), \n",
    "                  ngram_wiki_harm.drop(columns=['surprisal']),\n",
    "                  on=['code', 'sentid','subject'],\n",
    "                  how='inner')\n",
    "\n",
    "both_ngran_rnn['surprisal_1'] = rnn_wiki_harm['surprisal']\n",
    "both_ngran_rnn['surprisal_2'] = ngram_wiki_harm['surprisal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_surprisals = both_ngran_rnn['surprisal_1']\n",
    "ngram_surprisals = both_ngran_rnn['surprisal_2']\n",
    "\n",
    "\n",
    "plt.scatter(ngram_surprisals, rnn_surprisals)\n",
    "plt.xlabel('n-gram Model Surprisal')\n",
    "plt.ylabel('RNN Surprisal')\n",
    "plt.title('Relationship between n-gram Model Surprisal and RNN Surprisal')\n",
    "\n",
    "# Add linear line\n",
    "slope, intercept = np.polyfit(ngram_surprisals, rnn_surprisals, 1)\n",
    "x = np.linspace(min(ngram_surprisals), max(ngram_surprisals), 100)\n",
    "y = slope * x + intercept\n",
    "plt.plot(x, y, color='red', label='Linear')\n",
    "# plt.savefig('surprisal_relationship.png')  # Save the plot as an image file\n",
    "# add the eqaution of the line\n",
    "plt.text(10, 0.5, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The movie corpus RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename=download(\"movie-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = corpus.get_utterances_dataframe()\n",
    "conversations = corpus.get_conversations_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres_set = set(genre for sublist in conversations[\"meta.genre\"].apply(ast.literal_eval) for genre in sublist)\n",
    "unique_genre_lists = pd.DataFrame(conversations[\"meta.genre\"].apply(ast.literal_eval)).reset_index()['meta.genre'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique genres: {len(unique_genres_set)}\\nUnique genres lists: {len(unique_genre_lists)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts_single = conversations['meta.genre'].apply(ast.literal_eval).explode().value_counts().reset_index()\n",
    "genre_counts_single.columns = ['genre', 'count']\n",
    "genre_counts_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = conversations['meta.genre'].explode().value_counts().reset_index()\n",
    "genre_counts.columns = ['genre', 'count']\n",
    "genre_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## covert to txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances['genre'] = utterances['conversation_id'].apply(lambda cid: conversations.loc[cid]['meta.genre'] if cid in conversations.index else [])\n",
    "top_5_genres = genre_counts.head(5)['genre'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covert to txt file top 5 genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the folder \"movie_data\" and all its contents\n",
    "!rm -rf movie_data\n",
    "!mkdir -p movie_data\n",
    "genre_dict = {}\n",
    "\n",
    "for i,genre in enumerate(top_5_genres):\n",
    "    genre_utterances = utterances[utterances['genre'].apply(lambda genres: genre in genres)]\n",
    "    \n",
    "    # create a folder for each genre\n",
    "    !mkdir -p movie_data/{i}\n",
    "    path = f'movie_data/{i}'\n",
    "\n",
    "    # save the text to a file\n",
    "    genre_utterances['text'].to_csv(f'{path}/{i}_all.txt', index=False, header=False)\n",
    "    # remove all \" from the text file\n",
    "    !sed -i 's/\\\"//g' {path}/{i}_all.txt\n",
    "    \n",
    "    genre_dict[i] = genre\n",
    "    \n",
    "    # split into train and dev\n",
    "    !head -n 1000 {path}/{i}_all.txt > {path}/{i}_dev.txt\n",
    "    !tail -n +1001 {path}/{i}_all.txt > {path}/{i}_train.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in genre_dict:\n",
    "    checkpoint_to_use_movies = f\"../movie_data/{key}/ptb_model_{key}.pt\"\n",
    "    \n",
    "    model_file = f\"../movie_data/{key}/ptb_model_{key}.pt\"\n",
    "    vocab_file = f\"../movie_data/{key}/ptb_vocab.txt\"\n",
    "    data_dir = f\"../movie_data/{key}\"\n",
    "    trainfname = f\"{key}_train.txt\"\n",
    "    validfname = f\"{key}_dev.txt\"\n",
    "    surprisals = f\"../movie_data/{key}/rnn_surprisals_{key}.tsv\"\n",
    "    \n",
    "    !cd rnn && python main.py --cuda --model_file \"$model_file\" \\\n",
    "    --epochs \"$NUM_OF_EPOCHS\" \\\n",
    "    --vocab_file \"$vocab_file\" \\\n",
    "    --tied --data_dir \"$data_dir\" --trainfname \"$trainfname\" --validfname \"$validfname\"\n",
    "    \n",
    "    \n",
    "    !cd rnn && python main.py --cuda --model_file \"$checkpoint_to_use_movies\" \\\n",
    "    --vocab_file \"$vocab_file\" --data_dir './data' \\\n",
    "    --testfname 'brown.txt' --test --words --nopp > \"$surprisals\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text: str) -> str:\n",
    "    if text == '<unk>':\n",
    "        return text\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def harmonize(rt_data: pd.DataFrame, surprs_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create copies of the input DataFrames to avoid modifying the originals\n",
    "    crt_data = rt_data.copy()\n",
    "    csurprs_data = surprs_data.copy()\n",
    "    \n",
    "    # Drop unnecessary columns and remove duplicates from rt_data\n",
    "    crt_data.drop(['subject', 'word_in_exp', 'time'], axis=1, inplace=True)\n",
    "    crt_data.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remove end-of-sentence tokens from surprs_data\n",
    "    csurprs_data = csurprs_data[csurprs_data['token'] != '</s>']\n",
    "\n",
    "    # Identify and flag words containing spaces in crt_data\n",
    "    crt_data['remove_flag'] = crt_data['word'].apply(lambda word: ' ' in word)\n",
    "    \n",
    "    # Split and explode words containing spaces to match tokenization\n",
    "    crt_data['word'] = crt_data['word'].apply(lambda word: word.split())\n",
    "    crt_data = crt_data.explode('word')\n",
    "    \n",
    "    # Remove punctuation from both DataFrames\n",
    "    crt_data['word'] = crt_data['word'].apply(remove_punctuations)\n",
    "    csurprs_data['token'] = csurprs_data['token'].apply(remove_punctuations)\n",
    "\n",
    "    # Reset indices for merging\n",
    "    crt_data.reset_index(drop=True, inplace=True)\n",
    "    csurprs_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Merge DataFrames based on matching indices and drop unnecessary columns\n",
    "    if all(col in csurprs_data.columns for col in ['sentence_id', 'token_id']):\n",
    "        keys_harmony = crt_data.merge(csurprs_data, left_index=True, right_index=True).drop(['token_id'], axis=1)\n",
    "    else:\n",
    "        keys_harmony = crt_data.merge(csurprs_data, left_index=True, right_index=True).drop([ 'entropy', 'entred'], axis=1)\n",
    "\n",
    "    # Filter out flagged tokens and OOV words\n",
    "    keys_harmony = keys_harmony[keys_harmony['remove_flag'] == False]\n",
    "    keys_harmony = keys_harmony[keys_harmony['token'] != '<unk>']\n",
    "    \n",
    "    # Drop additional columns and merge with original rt_data\n",
    "    keys_harmony.drop(['text_id', 'text_pos', 'remove_flag', 'word'], axis=1, inplace=True)\n",
    "    final_harmony = keys_harmony.merge(rt_data, on='code')\n",
    "    \n",
    "    return final_harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized = {}\n",
    "for key in genre_dict:\n",
    "    readingTimes = pd.read_csv('https://gist.githubusercontent.com/omershubi/01b55eab89b81dc882055e0d27d61016/raw/046dbb7f0586b5dc1a368ee882f2cb923caad3df/brown-spr-data-for-pset.csv', index_col=0).sort_values(by='code')\n",
    "\n",
    "    rnn_movie = pd.read_csv(f'./movie_data/{key}/rnn_surprisals_{key}.tsv',sep=' ')\n",
    "    rnn_movie.rename(columns={'word': 'token'}, inplace=True)\n",
    "    rnn_movie.rename(columns={'surp': 'surprisal'}, inplace=True)\n",
    "    \n",
    "    # Harmonize the datasets\n",
    "    rnn_movie_harm = harmonize(readingTimes, rnn_movie)\n",
    "    harmonized[key] = rnn_movie_harm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in harmonized.keys():\n",
    "    print(f\"Genre {genre_dict[key]}:\")\n",
    "    print(harmonized[key].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_movie_harm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The human dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"li2017dailydialog/daily_dialog\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dialogs = dataset['train']['dialog']\n",
    "validation_data_dialogs = dataset['validation']['dialog']\n",
    "test_data_dialogs = dataset['test']['dialog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDialogToFile(df, filename):\n",
    "    for dialog in df:\n",
    "        for line in dialog:\n",
    "            with open(filename, 'a') as f:\n",
    "                f.write(line.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for movies, but with the daily dialog dataset\n",
    "!rm -rf human_data\n",
    "!mkdir -p human_data\n",
    "\n",
    "writeDialogToFile(train_data_dialogs, 'human_data/train.txt')\n",
    "writeDialogToFile(validation_data_dialogs, 'human_data/dev.txt')\n",
    "writeDialogToFile(test_data_dialogs, 'human_data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_to_use_human = f\"../human_data/ptb_model.pt\"\n",
    "\n",
    "model_file_human = f\"../human_data/ptb_model.pt\"\n",
    "vocab_file_human = f\"../human_data/ptb_vocab.txt\"\n",
    "data_dir_human= f\"../human_data\"\n",
    "trainfname_human = f\"train.txt\"\n",
    "validfname_human = f\"dev.txt\"\n",
    "surprisals_human = f\"../human_data/rnn_surprisals_human.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd rnn && python main.py --cuda --model_file \"$model_file_human\" \\\n",
    "--epochs \"$NUM_OF_EPOCHS\" \\\n",
    "--vocab_file \"$vocab_file_human\" \\\n",
    "--tied --data_dir \"$data_dir_human\" --trainfname \"$trainfname_human\" --validfname \"$validfname_human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd rnn && python main.py --cuda --model_file \"$checkpoint_to_use_human\" \\\n",
    "--vocab_file \"$vocab_file_human\" --data_dir './data' \\\n",
    "--testfname 'brown.txt' --test --words --nopp > \"$surprisals_human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readingTimes = pd.read_csv('https://gist.githubusercontent.com/omershubi/01b55eab89b81dc882055e0d27d61016/raw/046dbb7f0586b5dc1a368ee882f2cb923caad3df/brown-spr-data-for-pset.csv', index_col=0).sort_values(by='code')\n",
    "rnn_human = pd.read_csv(f'./human_data/rnn_surprisals_human.tsv',sep=' ')\n",
    "rnn_human.rename(columns={'word': 'token'}, inplace=True)\n",
    "rnn_human.rename(columns={'surp': 'human_surprisal'}, inplace=True)\n",
    "    \n",
    "# Harmonize the datasets\n",
    "rnn_human_harm = harmonize(readingTimes, rnn_human)\n",
    "harmonized_human= rnn_human_harm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rnn_model_correlations(rnn_movie, rnn_human, rnn_movie_key, rnn_human_key, rt_column):\n",
    "\n",
    "    # Calculate the correlation coefficients and p-values\n",
    "    rnn_movie_corr, _ = pearsonr(rnn_movie[rnn_movie_key], rnn_movie[rt_column])\n",
    "    rnn_human_corr, _ = pearsonr(rnn_human[rnn_human_key], rnn_human[rt_column])\n",
    "\n",
    "    # Compare the correlation coefficients\n",
    "    if rnn_movie_corr > rnn_human_corr:\n",
    "        percnt = (rnn_movie_corr - rnn_human_corr) / rnn_human_corr * 100\n",
    "        result = f\"RNN Movie has a higher correlation with human reading times (specifically {percnt:.4f}% higher).\"\n",
    "    elif rnn_movie_corr < rnn_human_corr:\n",
    "        percnt = (rnn_human_corr - rnn_movie_corr) / rnn_movie_corr * 100\n",
    "        result = f\"RNN Human has a higher correlation with human reading times (specifically {percnt:.4f}% higher).\"\n",
    "    else:\n",
    "        result = \"Both RNN models have the same correlation with human reading times.\"\n",
    "\n",
    "    return result, rnn_movie_corr, rnn_human_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in harmonized.items():\n",
    "    print(f\"Key:\\t{key} - {genre_dict[key]}\")\n",
    "    print(f\"Shape:\\t{value.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all harmonized correlations with human reading times\n",
    "correlations = {}\n",
    "for key, value in harmonized.items():\n",
    "    result, rnn_movie_corr, rnn_human_corr = compare_rnn_model_correlations(value, harmonized_human, 'surprisal', 'human_surprisal', 'time')\n",
    "    correlations[key] = (result, rnn_movie_corr, rnn_human_corr)\n",
    "    \n",
    "for key, value in correlations.items():\n",
    "    print(f\"Genre {genre_dict[key]}:\")\n",
    "    print(f\"\\t{value[0]}\")\n",
    "    print(f\"\\tRNN Movie correlation: {value[1]:.4f}\")\n",
    "    print(f\"\\tRNN Human correlation: {value[2]:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_genres_keys = []\n",
    "\n",
    "for key, value in harmonized.items():\n",
    "    genre = genre_dict[key]\n",
    "    rnn_movie_surprisals = value['surprisal']\n",
    "    rnn_human_surprisals = harmonized_human['human_surprisal']\n",
    "\n",
    "    # Ensure both series are the same length after dropping NaNs\n",
    "    min_length = min(len(rnn_movie_surprisals), len(rnn_human_surprisals))\n",
    "    rnn_movie_surprisals = rnn_movie_surprisals[:min_length]\n",
    "    rnn_human_surprisals = rnn_human_surprisals[:min_length]\n",
    "\n",
    "    # Plot the relationship\n",
    "    plt.scatter(rnn_movie_surprisals, rnn_human_surprisals)\n",
    "    plt.xlabel('RNN Movie Surprisal')\n",
    "    plt.ylabel('RNN Human Surprisal')\n",
    "    plt.title(f'Relationship between RNN Movie Surprisal and RNN Human Surprisal for {genre}')\n",
    "\n",
    "    # Add linear line\n",
    "    slope, intercept = np.polyfit(rnn_movie_surprisals, rnn_human_surprisals, 1)\n",
    "    x = np.linspace(min(rnn_movie_surprisals), max(rnn_movie_surprisals), 100)\n",
    "    y = slope * x + intercept\n",
    "    plt.plot(x, y, color='red', label='Linear')\n",
    "    plt.legend()\n",
    "\n",
    "    # Add the equation of the line\n",
    "    plt.text(0.05, max(rnn_human_surprisals)*0.95, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "\n",
    "    if slope > 0.01 or slope < -0.01:\n",
    "        good_genres_keys.append(key)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the genres with a significant slope are:\")\n",
    "for key in good_genres_keys:\n",
    "    print(f\"\\t{genre_dict[key]}, with key {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the top genres with at least some significants.\n",
    "Those are:\n",
    "\n",
    "\t['drama'], with key 0\n",
    "\n",
    "\t['comedy', 'romance'], with key 1\n",
    "\n",
    "\t['comedy', 'drama'], with key 3\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only the genres with a significant slope\n",
    "for key in good_genres_keys:\n",
    "    genre = genre_dict[key]\n",
    "    rnn_movie_surprisals = harmonized[key]['surprisal']\n",
    "    rnn_human_surprisals = harmonized_human['human_surprisal']\n",
    "\n",
    "    # Ensure both series are the same length after dropping NaNs\n",
    "    min_length = min(len(rnn_movie_surprisals), len(rnn_human_surprisals))\n",
    "    rnn_movie_surprisals = rnn_movie_surprisals[:min_length]\n",
    "    rnn_human_surprisals = rnn_human_surprisals[:min_length]\n",
    "\n",
    "    # Plot the relationship\n",
    "    plt.scatter(rnn_movie_surprisals, rnn_human_surprisals)\n",
    "    plt.xlabel('RNN Movie Surprisal')\n",
    "    plt.ylabel('RNN Human Surprisal')\n",
    "    plt.title(f'Relationship between RNN Movie Surprisal and RNN Human Surprisal for {genre}')\n",
    "\n",
    "    # Add linear line\n",
    "    slope, intercept = np.polyfit(rnn_movie_surprisals, rnn_human_surprisals, 1)\n",
    "    x = np.linspace(min(rnn_movie_surprisals), max(rnn_movie_surprisals), 100)\n",
    "    y = slope * x + intercept\n",
    "    plt.plot(x, y, color='red', label='Linear')\n",
    "    plt.legend()\n",
    "\n",
    "    # Add the equation of the line\n",
    "    plt.text(0.05, max(rnn_human_surprisals)*0.95, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting points here for us are points where the difference between the surprisal values. Lets find the top 5 points for each genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in good_genres_keys:\n",
    "    # keep only word and surprisal for RNN, and keep only unique rows\n",
    "    rnn_intrest = harmonized[key][['token', 'surprisal', 'sentid']].drop_duplicates()\n",
    "    human_intrest = rnn_human_harm[['token', 'human_surprisal', 'sentid']].drop_duplicates()\n",
    "    \n",
    "    k = 5\n",
    "    # get the top k words with the highest surprisal difference\n",
    "    top_k_uniqeue = pd.merge(rnn_intrest, human_intrest, on='token', how='inner', suffixes=('_rnn', '_human'))\n",
    "    top_k_uniqeue['diff'] = abs(top_k_uniqeue['surprisal'] - top_k_uniqeue['human_surprisal'])\n",
    "    top_k_uniqeue = top_k_uniqeue.sort_values(by='diff', ascending=False).drop_duplicates(subset='token').head(k)\n",
    "        \n",
    "    top_k = pd.merge(rnn_intrest, rnn_human_harm, on='token', how='inner', suffixes=('_rnn', '_human'))\n",
    "    top_k['diff'] = abs(top_k['surprisal'] - top_k['human_surprisal'])\n",
    "    top_k = top_k.sort_values(by='diff', ascending=False).head(k)\n",
    "\n",
    "    genre = genre_dict[key]\n",
    "    rnn_movie_surprisals = harmonized[key]['surprisal']\n",
    "    rnn_human_surprisals = harmonized_human['human_surprisal']\n",
    "    \n",
    "    # Ensure both series are the same length after dropping NaNs\n",
    "    min_length = min(len(rnn_movie_surprisals), len(rnn_human_surprisals))\n",
    "    rnn_movie_surprisals = rnn_movie_surprisals[:min_length]\n",
    "    rnn_human_surprisals = rnn_human_surprisals[:min_length]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.scatter(rnn_movie_surprisals, rnn_human_surprisals, color='blue', label='All other points')\n",
    "    plt.scatter(top_k['surprisal'], top_k['human_surprisal'], color='red', label=f'top {k} points with the highest difference')\n",
    "    plt.scatter(top_k_uniqeue['surprisal'], top_k_uniqeue['human_surprisal'], color='green', label = f'top {k} uniqeue points with the highest difference')\n",
    "\n",
    "    plt.xlabel('RNN movie Surprisal')\n",
    "    plt.ylabel(\"RNN human Surprisal\")\n",
    "    plt.title('Relationship between RNN movie and human Surprisal')\n",
    "\n",
    "    # Add linear line\n",
    "    slope, intercept = np.polyfit(rnn_human_surprisals, rnn_movie_surprisals, 1)\n",
    "    x = np.linspace(min(rnn_human_surprisals), max(rnn_human_surprisals), 100)\n",
    "    y = slope * x + intercept\n",
    "    plt.plot(x, y, color='red')\n",
    "\n",
    "    # add the equation of the line\n",
    "    plt.text(8, 30, f\"y = {slope:.4f}x + {intercept:.4f}\", fontsize=12, color='red')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in good_genres_keys:\n",
    "    # keep only word and surprisal for RNN, and keep only unique rows\n",
    "    rnn_intrest = harmonized[key][['token', 'surprisal', 'sentid']].drop_duplicates()\n",
    "    human_intrest = rnn_human_harm[['token', 'human_surprisal', 'sentid']].drop_duplicates()\n",
    "    \n",
    "    k = 5\n",
    "    # get the top k words with the highest surprisal difference\n",
    "    top_k_uniqeue = pd.merge(rnn_intrest, human_intrest, on='token', how='inner', suffixes=('_rnn', '_human'))\n",
    "    top_k_uniqeue['diff'] = abs(top_k_uniqeue['surprisal'] - top_k_uniqeue['human_surprisal'])\n",
    "    top_k_uniqeue = top_k_uniqeue.sort_values(by='diff', ascending=False).drop_duplicates(subset='token').head(k)\n",
    "        \n",
    "    top_k = pd.merge(rnn_intrest, rnn_human_harm, on='token', how='inner', suffixes=('_rnn', '_human'))\n",
    "    top_k['diff'] = abs(top_k['surprisal'] - top_k['human_surprisal'])\n",
    "    top_k = top_k.sort_values(by='diff', ascending=False).head(k)\n",
    "    \n",
    "    top_k_sent_id = top_k['sentid_rnn'].values\n",
    "    top_k_uniqeue_sent_id = top_k_uniqeue['sentid_rnn'].values\n",
    "    \n",
    "    sentances_top_k = []\n",
    "    sentances_top_k_uniqeue = []\n",
    "    sentances_in_both = []\n",
    "\n",
    "    for sent_id in top_k_sent_id:\n",
    "        sent = list(harmonized[key][harmonized[key]['sentid']==sent_id].drop_duplicates(subset='token')['token'])\n",
    "        sentances_top_k.append(' '.join(sent))\n",
    "        \n",
    "    for sent_id in top_k_uniqeue_sent_id:\n",
    "        sent = list(harmonized[key][harmonized[key]['sentid']==sent_id].drop_duplicates(subset='token')['token'])\n",
    "        sentances_top_k_uniqeue.append(' '.join(sent))\n",
    "        \n",
    "    # print the sentances nicely\n",
    "    print(f\"Genre {genre_dict[key]}:\")\n",
    "    print(f\"Top {k} sentances with the highest difference:\")\n",
    "    for i, sent in enumerate(sentances_top_k):\n",
    "        print(f\"\\t{i+1}. {sent}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Top {k} uniqeue sentances with the highest difference:\")\n",
    "    for i, sent in enumerate(sentances_top_k_uniqeue):\n",
    "        print(f\"\\t{i+1}. {sent}\")\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spillover for movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable for font size\n",
    "font_size = 16\n",
    "title_font_size = 20\n",
    "suptitle_font_size = 24\n",
    "\n",
    "for key in good_genres_keys:\n",
    "    genre = genre_dict[key]\n",
    "    rnn_movie_harm = harmonized[key]\n",
    "    positive_mean_rt = rnn_movie_harm[rnn_movie_harm['time'] > 0].reset_index()\n",
    "    surprisal_data = positive_mean_rt[['surprisal', 'time']].reset_index(drop=True)\n",
    "\n",
    "    # Calculate previous surprisal using pandas shift\n",
    "    surprisal_data['prev_surprisal'] = surprisal_data['surprisal'].shift(1).fillna(0)\n",
    "\n",
    "    # Calculate RNN probabilities\n",
    "    surprisal_data['rnn_prob_prev'] = 1 / (2 ** surprisal_data['prev_surprisal'])\n",
    "    surprisal_data['rnn_prob_current'] = 1 / (2 ** surprisal_data['surprisal'])\n",
    "\n",
    "    # Extract reading times\n",
    "    reading_times = surprisal_data['time']\n",
    "\n",
    "    # Perform linear regression\n",
    "    regression_coef_prev, intercept_prev = np.polyfit(surprisal_data['rnn_prob_prev'], reading_times, 1)\n",
    "    regression_coef_current, intercept_current = np.polyfit(surprisal_data['rnn_prob_current'], reading_times, 1)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "    # Plot RNN probability (previous word) vs next word's reading time\n",
    "    sns.regplot(x='rnn_prob_prev', y='time', data=surprisal_data, ax=ax1, scatter_kws={'color': 'blue'}, line_kws={'color': 'red'})\n",
    "    equation_prev = f'y = {regression_coef_prev:.2f}x + {intercept_prev:.2f}'\n",
    "    ax1.text(0.4, 0.8, equation_prev, transform=ax1.transAxes, fontsize=font_size, verticalalignment='top')\n",
    "    ax1.set_xlabel('RNN movie Predicted Probability of Previous Word', fontsize=font_size)\n",
    "    ax1.set_ylabel('Reading Time of Next Word (ms)', fontsize=font_size)\n",
    "    ax1.set_title('RNN movie Probability of Previous Word vs Next Word Reading Time', fontsize=title_font_size)\n",
    "\n",
    "    # Plot RNN probability (current word) vs next word's reading time\n",
    "    sns.regplot(x='rnn_prob_current', y='time', data=surprisal_data, ax=ax2, scatter_kws={'color': 'orange'}, line_kws={'color': 'red'})\n",
    "    equation_current = f'y = {regression_coef_current:.2f}x + {intercept_current:.2f}'\n",
    "    ax2.text(0.4, 0.8, equation_current, transform=ax2.transAxes, fontsize=font_size, verticalalignment='top')\n",
    "    ax2.set_xlabel('RNN movie Predicted Probability of Current Word', fontsize=font_size)\n",
    "    ax2.set_ylabel('Reading Time of Next Word (ms)', fontsize=font_size)\n",
    "    ax2.set_title('RNN movie Probability of Current Word vs Next Word Reading Time', fontsize=title_font_size)\n",
    "    \n",
    "    plt.suptitle(f'{genre}', fontsize=suptitle_font_size)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spillover for the human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mean_rt = rnn_human_harm[rnn_human_harm['time'] > 0].reset_index()\n",
    "surprisal_data = positive_mean_rt[['human_surprisal', 'time']].reset_index(drop=True)\n",
    "\n",
    "# Calculate previous surprisal using pandas shift\n",
    "surprisal_data['prev_surprisal'] = surprisal_data['human_surprisal'].shift(1).fillna(0)\n",
    "\n",
    "# Calculate RNN probabilities\n",
    "surprisal_data['rnn_prob_prev'] = 1 / (2 ** surprisal_data['prev_surprisal'])\n",
    "surprisal_data['rnn_prob_current'] = 1 / (2 ** surprisal_data['human_surprisal'])\n",
    "\n",
    "# Extract reading times\n",
    "reading_times = surprisal_data['time']\n",
    "\n",
    "# Perform linear regression\n",
    "regression_coef_prev, intercept_prev = np.polyfit(surprisal_data['rnn_prob_prev'], reading_times, 1)\n",
    "regression_coef_current, intercept_current = np.polyfit(surprisal_data['rnn_prob_current'], reading_times, 1)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "\n",
    "sns.regplot(x='rnn_prob_prev', y='time', data=surprisal_data, ax=ax1, scatter_kws={'color': 'blue'}, line_kws={'color': 'red'})\n",
    "equation_prev = f'y = {regression_coef_prev:.2f}x + {intercept_prev:.2f}'\n",
    "ax1.text(0.4, 0.8, equation_prev, transform=ax1.transAxes, fontsize=12, verticalalignment='top')\n",
    "ax1.set_xlabel('RNN human Predicted Probability of Previous Word')\n",
    "ax1.set_ylabel('Reading Time of Next Word (ms)')\n",
    "ax1.set_title('RNN human Probability of Previous Word vs Next Word Reading Time')\n",
    "\n",
    "sns.regplot(x='rnn_prob_current', y='time', data=surprisal_data, ax=ax2, scatter_kws={'color': 'orange'}, line_kws={'color': 'red'})\n",
    "equation_current = f'y = {regression_coef_current:.2f}x + {intercept_current:.2f}'\n",
    "ax2.text(0.4, 0.8, equation_current, transform=ax2.transAxes, fontsize=12, verticalalignment='top')\n",
    "ax2.set_xlabel('RNN human Predicted Probability of Current Word')\n",
    "ax2.set_ylabel('Reading Time of Next Word (ms)')\n",
    "ax2.set_title('RNN human Probability of Current Word vs Next Word Reading Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_overlap(data1: pd.DataFrame, data2: pd.DataFrame, column: str) -> float:\n",
    "    # Calculate the number of unique tokens\n",
    "    unique_tokens1 = data1[column].nunique()\n",
    "    unique_tokens2 = data2[column].nunique()\n",
    "    \n",
    "    # Calculate the number of unique tokens that appear in both datasets\n",
    "    unique_tokens_overlap = len(set(data1[column].unique()).intersection(set(data2[column].unique())))\n",
    "    \n",
    "    # Calculate the percentage of unique tokens that appear in both datasets\n",
    "    overlap_percentage = unique_tokens_overlap / unique_tokens1 * 100\n",
    "\n",
    "    return overlap_percentage\n",
    "\n",
    "for key in good_genres_keys:\n",
    "    genre = genre_dict[key]\n",
    "    rnn_movie_harm = harmonized[key]\n",
    "    rnn_human_harm = harmonized_human\n",
    "\n",
    "    # word overlap\n",
    "    overlap_percentage = word_overlap(rnn_movie_harm, rnn_human_harm, 'token')\n",
    "    print(f\"Word Overlap between RNN Movie and RNN Human ({genre}):{overlap_percentage:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done in\", time.time() - start, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Spark (local)",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
